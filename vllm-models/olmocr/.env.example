# Configuración específica para el modelo OlmOCR

# Modelo
MODEL_NAME=olmocr
VLLM_MODEL=allenai/olmOCR-7B-0825-FP8

# Configuración GPU
CUDA_VISIBLE_DEVICES=0
GPU_MEMORY_UTILIZATION=0.5

# Configuración del servidor
HOST=0.0.0.0
PORT=8001
MAX_MODEL_LEN=2048

# Configuración de rendimiento
TENSOR_PARALLEL_SIZE=1
MAX_NUM_BATCHED_TOKENS=8192

# Logging
VLLM_LOGGING_LEVEL=WARNING

# Nombres de servicios y containers
SERVICE_NAME=vllm-olmocr
CONTAINER_NAME=vllm-olmocr

# Parámetros vLLM (se usan en docker-compose command)
VLLM_MODEL_PATH=${VLLM_MODEL}
VLLM_HOST=${HOST}
VLLM_PORT=${PORT}
VLLM_SERVED_MODEL_NAME=${MODEL_NAME}
VLLM_MAX_MODEL_LEN=${MAX_MODEL_LEN}
VLLM_GPU_MEMORY_UTILIZATION=${GPU_MEMORY_UTILIZATION}
VLLM_TENSOR_PARALLEL_SIZE=${TENSOR_PARALLEL_SIZE}
VLLM_MAX_NUM_BATCHED_TOKENS=${MAX_NUM_BATCHED_TOKENS}